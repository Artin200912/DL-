{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1cyc-_SRYPT4d5fl-JcQOwiliKpjPD9Y6",
      "authorship_tag": "ABX9TyModKe+me0536ftJk/YUcwc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Artin200912/DL-/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import os"
      ],
      "metadata": {
        "id": "uM6DJSliDkuD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHm1pwgUlFSl",
        "outputId": "6488ce7a-8173-4d1d-fd6a-80566bf55d0a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "defining the dataset path"
      ],
      "metadata": {
        "id": "Kd2LSHLkINlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/face-expression-recognition-dataset'\n",
        "data_train = \"/content/face-expression-recognition-dataset/images/train\"\n",
        "data_test = \"/content/emotion-detection-fer/test\"\n",
        "data_validation = \"/content/face-expression-recognition-dataset/images/validation\""
      ],
      "metadata": {
        "id": "H5rjUYkqHi2o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas\n",
        "\n",
        "od.download(\n",
        "\t\"https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6GdczLeKeow",
        "outputId": "ee628e18-d3e4-457f-82ee-d0da98622324"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: artindaneshvar\n",
            "Your Kaggle Key: ··········\n",
            "Downloading face-expression-recognition-dataset.zip to ./face-expression-recognition-dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 121M/121M [00:00<00:00, 159MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((48, 48)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "BAU21IRYIKqZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(ImageFolder):\n",
        "  def __init__(self, root_dir, transform=None):\n",
        "    super(CustomDataset, self).__init__(root=root_dir, transform=transform)"
      ],
      "metadata": {
        "id": "eN-f51L8I2LZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(self):\n",
        "  images = []\n",
        "  for Images in self.classes:\n",
        "    class_path = os.path.join(self.root_dir, Images)\n",
        "    class_idx = self.class_to_idx[Images]\n",
        "    for img_name in os.listdir(class_path):\n",
        "      img_path = os.path.join(class_path, img_name)\n",
        "      images.append((img_path, class_idx))\n",
        "    return images"
      ],
      "metadata": {
        "id": "i-ebYEqFJfE2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __len__(self):\n",
        "  return len(self.images)"
      ],
      "metadata": {
        "id": "yzPF9irrO5wi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __Get_item__(self, idx):\n",
        "  img_path, label = self.images[idx]\n",
        "  image = Image.open(img_path).convert(\"L\")\n",
        "  if self.transform:\n",
        "    image = self.transform(image)\n",
        "\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "obYEoK1_PCE8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(root_dir=data_train, transform=transform)\n",
        "test_dataset = CustomDataset(root_dir=data_test, transform=transform)\n",
        "validation_dataset = CustomDataset(root_dir=data_validation, transform=transform)\n"
      ],
      "metadata": {
        "id": "T6XX9DOSPeZF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "IGHSAjEfQOtH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(EmotionNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    self.FullyConneted1 = nn.Linear(128 * 6 * 6, 512)\n",
        "    self.FullyConneted2 = nn.Linear(512, 7)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "    x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "    x = self.pool(nn.functional.relu(self.conv3(x)))\n",
        "    x = x.view(-1, 128 * 6 * 6)\n",
        "    x = nn.functional.relu(self.FullyConneted1(x))\n",
        "    x = nn.functional.sigmoid(self.FullyConneted2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "tYSOSY3_SIWm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EmotionNN()"
      ],
      "metadata": {
        "id": "fazcDxPpUcRC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "02dwKkxeU-Ws"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_epochs = 7\n",
        "for epoch in range(num_of_epochs):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  for images, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1} / {num_of_epochs}'):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = loss_func(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch {epoch + 1}/{num_of_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "print(\"Training Loop finished successfully\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PutfMz5FVW7C",
        "outputId": "c16e3e65-9c17-4421-d2b1-ab85c47850ad"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 / 7: 100%|██████████| 451/451 [02:16<00:00,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7, Loss: 1.7888593179423635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 / 7: 100%|██████████| 451/451 [02:27<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/7, Loss: 1.727196387599683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 / 7: 100%|██████████| 451/451 [02:27<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/7, Loss: 1.6866658143616569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 / 7: 100%|██████████| 451/451 [02:31<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/7, Loss: 1.6625365745730516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 / 7: 100%|██████████| 451/451 [02:28<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/7, Loss: 1.6398299691946703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 / 7: 100%|██████████| 451/451 [02:35<00:00,  2.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/7, Loss: 1.6182557109189932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 / 7: 100%|██████████| 451/451 [03:02<00:00,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7, Loss: 1.5951401058691832\n",
            "Training Loop finished successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0"
      ],
      "metadata": {
        "id": "u7CgVPckhpcZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK46BqN9hvaY",
        "outputId": "67d129f0-4686-4194-bbbe-cf269d05e157"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 113/113 [00:17<00:00,  6.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = correct / total\n",
        "print(f'Accuracy on test set{accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdzQx-jxiNnI",
        "outputId": "a4afef96-55e3-462a-d424-5a13a7ab9e31"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set52.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'project_model.pth')"
      ],
      "metadata": {
        "id": "KUDrm0KxivXl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EmotionNN()\n",
        "model.load_state_dict(torch.load('project_model.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUqFz_s4jEp1",
        "outputId": "1a859905-2321-43be-8369-7ea0a29a84ae"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmotionNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (FullyConneted1): Linear(in_features=4608, out_features=512, bias=True)\n",
              "  (FullyConneted2): Linear(in_features=512, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predictions.extend(predicted.numpy())"
      ],
      "metadata": {
        "id": "t6hFu_cejOuZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = Image.open('/content/smile.jpg')\n",
        "input_tensor = transform(input_image).unsqueeze(0)\n",
        "emotion_mapping = {0: 'Angry', 1: 'Happy', 2: 'Sad', 3: 'Surprised', 4: 'Neutral'}"
      ],
      "metadata": {
        "id": "blPGTXt0jtVk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    output = model(input_tensor)\n",
        "    _, predicted_label = torch.max(output, 1)\n",
        "\n",
        "print(f'Predicted emotion is {predicted_label.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tlPND8bjdne",
        "outputId": "a89707f1-10c1-44e7-8c1c-98361a0b2cc4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted emotion is 2\n"
          ]
        }
      ]
    }
  ]
}